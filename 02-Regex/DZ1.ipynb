{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1"
      ],
      "metadata": {
        "id": "mrjNc7G1p8Dj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZxsb0J5pQyX",
        "outputId": "a445273b-dff0-4a48-8c80-ec0f7ba976ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|>\n",
            "(\n",
            ")\n",
            ",\n",
            "-\n",
            ".\n",
            ":\n",
            "H\n",
            "I\n",
            "N\n",
            "T\n",
            "a\n",
            "b\n",
            "c\n",
            "d\n",
            "e\n",
            "f\n",
            "g\n",
            "h\n",
            "i\n",
            "k\n",
            "l\n",
            "m\n",
            "n\n",
            "o\n",
            "p\n",
            "q\n",
            "r\n",
            "s\n",
            "t\n",
            "u\n",
            "v\n",
            "w\n",
            "x\n",
            "y\n",
            "z\n",
            "\n",
            "th\n",
            "a\n",
            "nd\n",
            "o\n",
            "the\n",
            "w\n",
            "the\n",
            "le\n",
            "in\n",
            "or\n",
            "h\n",
            "it\n",
            "ro\n",
            "and\n",
            "s\n",
            "on\n",
            "ed\n",
            "t\n",
            "d\n",
            "f\n",
            "ll\n",
            "p\n",
            "wi\n",
            "c\n",
            "lo\n",
            "ho\n",
            "b\n",
            "ing\n",
            "om\n",
            "er\n",
            "und\n",
            "with\n",
            "of\n",
            "to\n",
            "ow\n",
            "m\n",
            "ro\n",
            "he\n",
            "in\n",
            "g\n",
            "as\n",
            "ir\n",
            "ar\n",
            "an\n",
            "ha\n",
            "id\n",
            "ts\n",
            "oms\n",
            "l\n",
            "hob\n",
            "hobb\n",
            "hobbit\n",
            "n\n",
            "et\n",
            "led\n",
            "it\n",
            "round\n",
            "en\n",
            "T\n",
            "The\n",
            "tu\n",
            "el\n",
            "for\n",
            "es\n",
            "hole\n",
            "li\n",
            "ot\n",
            "e\n",
            "me\n",
            "sa\n",
            "ole\n",
            "ly\n",
            "do\n",
            "door\n",
            "ke\n",
            "tun\n",
            "tunn\n",
            "tunnel\n",
            "ver\n",
            "ut\n",
            "is\n",
            "air\n",
            "lo\n",
            "-\n",
            "oing\n",
            "sid\n",
            "side\n",
            "all\n",
            "rooms\n",
            "(\n",
            "),\n",
            "wer\n",
            "were\n",
            "ows\n",
            "re\n",
            "N\n",
            "ty\n",
            "lled\n",
            "an\n",
            "y\n",
            "dow\n",
            "down\n",
            "at\n",
            "was\n",
            "hole\n",
            "me\n",
            "com\n",
            "comf\n",
            "comfor\n",
            "comfort\n",
            "had\n",
            "ct\n",
            "like\n",
            "ell\n",
            "ass\n",
            "k\n",
            "op\n",
            "open\n",
            "opened\n",
            "pan\n",
            "flo\n",
            "floor\n",
            "airs\n",
            "lots\n",
            "pe\n",
            "ond\n",
            "going\n",
            "tr\n",
            "ill\n",
            "man\n",
            "many\n",
            "st\n",
            "thes\n",
            "these\n",
            "ard\n",
            "rooms\n",
            "de\n",
            "same\n",
            "wind\n",
            "windows\n",
            "In\n",
            "gro\n",
            "ground\n",
            "there\n",
            "liv\n",
            "lived\n",
            "Not\n",
            "nas\n",
            "nasty\n",
            "dir\n",
            "dirty\n",
            "wet\n",
            "fi\n",
            "filled\n",
            "end\n",
            "ends\n",
            "wor\n",
            "worm\n",
            "worms\n",
            "oo\n",
            "ooz\n",
            "oozy\n",
            "sme\n",
            "smell\n",
            "nor\n",
            "yet\n",
            "dr\n",
            "dry\n",
            "bar\n",
            "bare\n",
            "sand\n",
            "sandy\n",
            "no\n",
            "noth\n",
            "nothing\n",
            "sit\n",
            "or\n",
            "eat\n",
            "th\n",
            "that\n",
            "mean\n",
            "means\n",
            "I\n",
            "It\n",
            "per\n",
            "perf\n",
            "perfe\n",
            "perfect\n",
            "perfectly\n",
            "por\n",
            "porth\n",
            "porthole\n",
            "pa\n",
            "pain\n",
            "paint\n",
            "painted\n",
            "gre\n",
            "green\n",
            "sh\n",
            "shin\n",
            "shiny\n",
            "yell\n",
            "yellow\n",
            "br\n",
            "brass\n",
            "kn\n",
            "kno\n",
            "knob\n",
            "ex\n",
            "exa\n",
            "exact\n",
            "mid\n",
            "midd\n",
            "middle\n",
            "tub\n",
            "tube\n",
            "sh\n",
            "sha\n",
            "shap\n",
            "shaped\n",
            "hall\n",
            "ver\n",
            "very\n",
            "comforta\n",
            "comfortab\n",
            "comfortable\n",
            "witho\n",
            "without\n",
            "sm\n",
            "smo\n",
            "smoke\n",
            "panel\n",
            "panelled\n",
            "wa\n",
            "wall\n",
            "walls\n",
            "floors\n",
            "ti\n",
            "tiled\n",
            "car\n",
            "carp\n",
            "carpet\n",
            "carpeted\n",
            "pro\n",
            "prov\n",
            "provid\n",
            "provided\n",
            "po\n",
            "pol\n",
            "polis\n",
            "polish\n",
            "polished\n",
            "ch\n",
            "chairs\n",
            "peg\n",
            "pegs\n",
            "hats\n",
            "co\n",
            "coa\n",
            "coats\n",
            "fond\n",
            "v\n",
            "vis\n",
            "visit\n",
            "visitor\n",
            "visitors\n",
            "wo\n",
            "wound\n",
            "fair\n",
            "fairly\n",
            "but\n",
            "not\n",
            "q\n",
            "qu\n",
            "quit\n",
            "quite\n",
            "str\n",
            "stra\n",
            "strai\n",
            "straig\n",
            "straigh\n",
            "straight\n",
            "int\n",
            "into\n",
            "hill\n",
            "H\n",
            "Hill\n",
            "as\n",
            "peo\n",
            "peop\n",
            "people\n",
            "mi\n",
            "mile\n",
            "miles\n",
            "ca\n",
            "called\n",
            "lit\n",
            "litt\n",
            "little\n",
            "doors\n",
            "out\n",
            "fir\n",
            "first\n",
            "one\n",
            "then\n",
            "ano\n",
            "anothe\n",
            "another\n",
            "No\n",
            "u\n",
            "up\n",
            "upst\n",
            "upstairs\n",
            "bed\n",
            "bedrooms\n",
            "ba\n",
            "bath\n",
            "bathrooms\n",
            "cell\n",
            "cellar\n",
            "cellars\n",
            "pantr\n",
            "pantri\n",
            "pantries\n",
            "lots\n",
            "ward\n",
            "wardro\n",
            "wardrob\n",
            "wardrobes\n",
            "whole\n",
            "dev\n",
            "devot\n",
            "devoted\n",
            "clo\n",
            "clothe\n",
            "clothes\n",
            "kit\n",
            "kitc\n",
            "kitche\n",
            "kitchen\n",
            "kitchens\n",
            "din\n",
            "dining\n",
            "i\n",
            "ind\n",
            "inde\n",
            "indeed\n",
            "pass\n",
            "passa\n",
            "passag\n",
            "passage\n",
            "bes\n",
            "best\n",
            "le\n",
            "lef\n",
            "lefth\n",
            "leftha\n",
            "lefthand\n",
            "going\n",
            "only\n",
            "ones\n",
            "hav\n",
            "have\n"
          ]
        }
      ],
      "source": [
        "#Взято с https://huggingface.co/learn/nlp-course/chapter6/5?fw=pt и немного переделан вывод...\n",
        "\n",
        "#!pip install transformer\n",
        "from transformers import AutoTokenizer\n",
        "from collections import defaultdict\n",
        "\n",
        "corpus = [\"In a hole in the ground there lived a hobbit. Not a nasty, dirty, wet hole, filled with the ends of worms and an oozy smell, nor yet a dry, bare, sandy hole with nothing in it to sit down on or to eat: it was a hobbit-hole, and that means comfort. It had a perfectly round door like a porthole, painted green, with a shiny yellow brass knob in the exact middle. The door opened on to a tube-shaped hall like a tunnel: a very comfortable tunnel without smoke, with panelled walls, and floors tiled and carpeted, provided with polished chairs, and lots and lots of pegs for hats and coats - the hobbit was fond of visitors. The tunnel wound on and on, going fairly but not quite straight into the side of the hill - The Hill, as all the people for many miles round called it - and many little round doors opened out of it, first on one side and then on another. No going upstairs for the hobbit: bedrooms, bathrooms, cellars, pantries (lots of these), wardrobes (he had whole rooms devoted to clothes), kitchens, dining-rooms, all were on the same floor, and indeed on the same passage. The best rooms were all on the lefthand side (going in), for these were the only ones to have windows, deep-set round windows looking over his garden, and meadows beyond, sloping down to the river.\"]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\") #(пре)токенизатор из GPT2\n",
        "\n",
        "word_freqs = defaultdict(int)\n",
        "\n",
        "for text in corpus: #тут вычисляется частотность слов в исходном тексте.\n",
        "    words_with_offsets = tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
        "    new_words = [word for word, offset in words_with_offsets]\n",
        "    for word in new_words:\n",
        "        word_freqs[word] += 1\n",
        "\n",
        "alphabet = [] #массив алфавита\n",
        "\n",
        "for word in word_freqs.keys(): #в него закидываются все буквы (из входного текста)\n",
        "    for letter in word:\n",
        "        if letter not in alphabet:\n",
        "            alphabet.append(letter)\n",
        "alphabet.sort()\n",
        "\n",
        "vocab = [\"<|endoftext|>\"] + alphabet.copy() #тег конца текста и словарь закидываются в словарь.\n",
        "splits = {word: [c for c in word] for word in word_freqs.keys()}\n",
        "\n",
        "def compute_pair_freqs(splits): #происходит разделение слов на буквы...\n",
        "    pair_freqs = defaultdict(int)\n",
        "    for word, freq in word_freqs.items():\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            continue\n",
        "        for i in range(len(split) - 1):\n",
        "            pair = (split[i], split[i + 1])\n",
        "            pair_freqs[pair] += freq\n",
        "    return pair_freqs\n",
        "\n",
        "\n",
        "pair_freqs = compute_pair_freqs(splits)\n",
        "\n",
        "best_pair = \"\"\n",
        "max_freq = None\n",
        "\n",
        "for pair, freq in pair_freqs.items(): #нахождение самой частотной пары\n",
        "    if max_freq is None or max_freq < freq:\n",
        "        best_pair = pair\n",
        "        max_freq = freq\n",
        "\n",
        "def merge_pair(a, b, splits): #здесь происходит объединение пары\n",
        "    for word in word_freqs:\n",
        "        split = splits[word]\n",
        "        if len(split) == 1:\n",
        "            continue\n",
        "\n",
        "        i = 0\n",
        "        while i < len(split) - 1:\n",
        "            if split[i] == a and split[i + 1] == b:\n",
        "                split = split[:i] + [a + b] + split[i + 2 :]\n",
        "            else:\n",
        "                i += 1\n",
        "        splits[word] = split\n",
        "    return splits\n",
        "\n",
        "vocab_size = 400 #400 наш максимум\n",
        "\n",
        "while len(vocab) < vocab_size: #тут какая-то магия объединяет всё в финальный словарь\n",
        "    pair_freqs = compute_pair_freqs(splits)\n",
        "    best_pair = \"\"\n",
        "    max_freq = None\n",
        "    for pair, freq in pair_freqs.items():\n",
        "        if max_freq is None or max_freq < freq:\n",
        "            best_pair = pair\n",
        "            max_freq = freq\n",
        "    splits = merge_pair(*best_pair, splits)\n",
        "    merges[best_pair] = best_pair[0] + best_pair[1]\n",
        "    vocab.append(best_pair[0] + best_pair[1])\n",
        "\n",
        "for elem in vocab:\n",
        "  print (elem.replace('Ġ',''), sep='\\n') #вывожу словарь без символа Ġ, который там, кажется, служебный."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2"
      ],
      "metadata": {
        "id": "BXnd_8x_qBT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#сам алгоритм вычислений взят на Хабре, я дописал сюда всё связанное с выводом матрицы.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "str_1 = 'программирование'\n",
        "str_2 = 'лингвистика'\n",
        "\n",
        "check = 0\n",
        "matrix = [] #тут будет матрица со всеми цифрами\n",
        "\n",
        "n, m = len(str_1), len(str_2) #строки на вход\n",
        "if n > m: #m должно быть длиннее n, меняем порядок\n",
        "\tstr_1, str_2 = str_2, str_1\n",
        "\tn, m = m, n\n",
        "\tcheck = 1\n",
        "\n",
        "\n",
        "def levenstein(str_1, str_2):\n",
        "\n",
        "    current_row = range (n + 1) #нулевой ряд от 0 до n+1\n",
        "    for i in range (1, m + 1): #алгоритм в цикле\n",
        "        previous_row, current_row = current_row, [i] + [0] * n #нынешний ряд -> предыдущий,\n",
        "        matrix.append(list(previous_row)) #запись матрицы\n",
        "        for j in range (1, n + 1): #двигаемся по строчке в цикле\n",
        "            add, delete, change = previous_row[j] + 1, current_row[j - 1] + 1, previous_row[j - 1] #у нас три значения: D(i,j-1), D(i-1,j) и D(i-1,j-1) + m (S1[i], S2[j])\n",
        "            if str_1[j - 1] != str_2[i - 1]: #если буквы разные\n",
        "                change += 1 #записываем единицу в m\n",
        "            current_row[j] = min(add, delete, change) #находим из них минимальное и записываем его в таблицу\n",
        "    matrix.append (current_row) #запись последнего ряда в матрицу\n",
        "\n",
        "    return current_row[n]\n",
        "\n",
        "placeholder = [' '] #ниже строки для того, чтобы дописать слова в таблицу с числами.\n",
        "\n",
        "def tables (str_1, str_2, df):\n",
        "\tdf.columns = placeholder+[*str_1]\n",
        "\tdf.index = placeholder+[*str_2]\n",
        "\treturn 0\n",
        "\n",
        "levenstein (str_1, str_2) #инициализация функции\n",
        "df = pd.DataFrame (matrix)\n",
        "tables (str_1, str_2, df) #дописываем\n",
        "\n",
        "print ('результат: ', levenstein (str_1, str_2), '\\n', '\\n')\n",
        "#print('\\n'.join(['\\t'.join([str(cell) for cell in row]) for row in matrix]))\n",
        "print (df, '\\n\\n')\n",
        "\n",
        "#а для levenshtein и einstein там 5 будет"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yO04TztqS3J",
        "outputId": "0408c2e3-22c3-432e-bbc0-ec672fbb0a56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "результат:  13 \n",
            " \n",
            "\n",
            "        л   и   н   г   в   и   с   т   и   к   а\n",
            "    0   1   2   3   4   5   6   7   8   9  10  11\n",
            "п   1   1   2   3   4   5   6   7   8   9  10  11\n",
            "р   2   2   2   3   4   5   6   7   8   9  10  11\n",
            "о   3   3   3   3   4   5   6   7   8   9  10  11\n",
            "г   4   4   4   4   3   4   5   6   7   8   9  10\n",
            "р   5   5   5   5   4   4   5   6   7   8   9  10\n",
            "а   6   6   6   6   5   5   5   6   7   8   9   9\n",
            "м   7   7   7   7   6   6   6   6   7   8   9  10\n",
            "м   8   8   8   8   7   7   7   7   7   8   9  10\n",
            "и   9   9   8   9   8   8   7   8   8   7   8   9\n",
            "р  10  10   9   9   9   9   8   8   9   8   8   9\n",
            "о  11  11  10  10  10  10   9   9   9   9   9   9\n",
            "в  12  12  11  11  11  10  10  10  10  10  10  10\n",
            "а  13  13  12  12  12  11  11  11  11  11  11  10\n",
            "н  14  14  13  12  13  12  12  12  12  12  12  11\n",
            "и  15  15  14  13  13  13  12  13  13  12  13  12\n",
            "е  16  16  15  14  14  14  13  13  14  13  13  13 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 3"
      ],
      "metadata": {
        "id": "sfC-0GXjqNZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "txt = \"why_n-ot@why.ru.jp\"\n",
        "x = re.search(\"[\\w-]+@[\\w+-]+\\\\.[\\w.]+\", txt) #может понимать разные домены первого уровня\n",
        "\n",
        "if x:\n",
        "  print(\"Works\")\n",
        "else:\n",
        "  print(\"Doesn't work\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjEVFh0DqEkk",
        "outputId": "7f8d3e0e-89d4-44d5-c903-36b390af5d74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Works\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "txt = \"/mnt/c/Windows/System32/drivers/etc/hosts.txt\"\n",
        "x = re.search(\"/|^$\\w:|^$(?:[\\\\/]\\w+\\.\\w+)\", txt)\n",
        "\n",
        "if x:\n",
        "  print(\"Works\")\n",
        "else:\n",
        "  print(\"Doesn't work\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7m3OQADp7gs",
        "outputId": "09f99f28-12a0-4f81-f0a4-037a439488f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Works\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "txt = \"\"\" #[[Time: Обычно\"обычно:#frequentative_adverbs_adj:FREQUENTATIVE\"] [Experiencer_Metaphoric: бюджет\"бюджет:бюджет:BUDGET\"] [[ко\"к:#preposition:PREPOSITION\"] [OrderInTimeAndSpace: второму\"второй:TWO_ORDINAL\"] Object_Situation: чтению \"чтение:READING_OF_THE_DRAFT_LAW\"] Predicate: готовится\"готовить:готовить:PREPAREDNESS\" [[DegreeApproximative: непосредственно\"непосредственный:DIRECT_OBLIQUE\"] [в\"в_Prepositional:#preposition:PREPOSITION\"] Locative: Думе\"дума:дума:DUMA\"]#: [[Agent: депутаты\"депутат:депутат:DEPUTY\"] Specification_Clause: корректируют\"корректировать:корректировать:TO_CORRECT\" [[Agent: правительственные\"правительство:правительство:GOVERNMENT\"] Object_Situation: планы\"план:план:SCHEDULE_FOR_ACTIVITY\"]]]. \"\"\"\n",
        "\n",
        "occ = re.findall('\\[(\\w+): ', txt) #сем. роль\n",
        "occ1 = re.findall(': (\\w+)\\\"', txt) #слово\n",
        "occ2 = re.findall('\\\"(\\w+):', txt) #лемма\n",
        "occ3 = re.findall(':(#\\w+|\\w+):', txt) #лексический класс\n",
        "occ4 = re.findall(':(\\w+)\\\"[\\] ]', txt) #семантический класс\n",
        "\n",
        "\n",
        "print(occ, occ1, occ2, occ3, occ4, sep='\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-MjqIJbqMBj",
        "outputId": "cfe69a31-cd9d-4887-b587-14b2c2dfec28"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Time', 'Experiencer_Metaphoric', 'OrderInTimeAndSpace', 'DegreeApproximative', 'Agent', 'Agent']\n",
            "\n",
            "['Обычно', 'бюджет', 'второму', 'готовится', 'непосредственно', 'Думе', 'депутаты', 'корректируют', 'правительственные', 'планы']\n",
            "\n",
            "['обычно', 'бюджет', 'к', 'второй', 'чтение', 'готовить', 'непосредственный', 'в_Prepositional', 'дума', 'депутат', 'корректировать', 'правительство', 'план']\n",
            "\n",
            "['#frequentative_adverbs_adj', 'бюджет', '#preposition', 'готовить', '#preposition', 'дума', 'депутат', 'корректировать', 'правительство', 'план']\n",
            "\n",
            "['FREQUENTATIVE', 'BUDGET', 'PREPOSITION', 'TWO_ORDINAL', 'READING_OF_THE_DRAFT_LAW', 'PREPAREDNESS', 'DIRECT_OBLIQUE', 'PREPOSITION', 'DUMA', 'DEPUTY', 'TO_CORRECT', 'GOVERNMENT', 'SCHEDULE_FOR_ACTIVITY']\n"
          ]
        }
      ]
    }
  ]
}